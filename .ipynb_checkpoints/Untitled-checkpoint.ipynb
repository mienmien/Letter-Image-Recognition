{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "667c3e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:4.1828, val_loss:3.9698\n",
      "epoch [2/100], loss:1.2469, val_loss:0.9878\n",
      "epoch [3/100], loss:0.7639, val_loss:0.6578\n",
      "epoch [4/100], loss:0.5025, val_loss:0.3946\n",
      "epoch [5/100], loss:0.3229, val_loss:0.2722\n",
      "epoch [6/100], loss:0.2426, val_loss:0.1986\n",
      "epoch [7/100], loss:0.1885, val_loss:0.1487\n",
      "epoch [8/100], loss:0.1765, val_loss:0.1174\n",
      "epoch [9/100], loss:0.1089, val_loss:0.1049\n",
      "epoch [10/100], loss:0.0867, val_loss:0.0695\n",
      "epoch [11/100], loss:0.0609, val_loss:0.0597\n",
      "epoch [12/100], loss:0.0449, val_loss:0.0432\n",
      "epoch [13/100], loss:0.0278, val_loss:0.0303\n",
      "epoch [14/100], loss:0.0224, val_loss:0.0232\n",
      "epoch [15/100], loss:0.0215, val_loss:0.0206\n",
      "epoch [16/100], loss:0.0219, val_loss:0.0199\n",
      "epoch [17/100], loss:0.0179, val_loss:0.0165\n",
      "epoch [18/100], loss:0.0242, val_loss:0.0200\n",
      "epoch [19/100], loss:0.0176, val_loss:0.0194\n",
      "epoch [20/100], loss:0.0140, val_loss:0.0150\n",
      "epoch [21/100], loss:0.0142, val_loss:0.0204\n",
      "epoch [22/100], loss:0.0135, val_loss:0.0144\n",
      "epoch [23/100], loss:0.0249, val_loss:0.0334\n",
      "epoch [24/100], loss:0.0058, val_loss:0.0090\n",
      "epoch [25/100], loss:0.0056, val_loss:0.0053\n",
      "epoch [26/100], loss:0.0066, val_loss:0.0071\n",
      "epoch [27/100], loss:0.0133, val_loss:0.0102\n",
      "epoch [28/100], loss:0.0026, val_loss:0.0057\n",
      "epoch [29/100], loss:0.0080, val_loss:0.0038\n",
      "epoch [30/100], loss:0.0041, val_loss:0.0026\n",
      "epoch [31/100], loss:0.0188, val_loss:0.0232\n",
      "epoch [32/100], loss:0.0045, val_loss:0.0041\n",
      "epoch [33/100], loss:0.0025, val_loss:0.0020\n",
      "epoch [34/100], loss:0.0058, val_loss:0.0024\n",
      "epoch [35/100], loss:0.0067, val_loss:0.0048\n",
      "epoch [36/100], loss:0.0064, val_loss:0.0063\n",
      "epoch [37/100], loss:0.0025, val_loss:0.0027\n",
      "epoch [38/100], loss:0.0023, val_loss:0.0020\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 讀取訓練和測試數據\n",
    "train_data = pd.read_csv('training.csv')\n",
    "test_data = pd.read_csv('test_X.csv')\n",
    "\n",
    "# 將字母標籤轉換為二元形式\n",
    "train_data['lettr'] = train_data['lettr'].apply(lambda x: 1 if x in ['B','H','P','W','R','M'] else -1)\n",
    "\n",
    "# 切分訓練數據的特徵和標籤\n",
    "X_train = train_data.drop('lettr', axis=1)\n",
    "y_train = train_data['lettr']\n",
    "\n",
    "# 使用StandardScaler進行數據正規化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "\n",
    "# 將資料轉換為 torch.Tensor\n",
    "X_train_tensor = torch.Tensor(X_train_scaled)\n",
    "X_test_tensor = torch.Tensor(X_test_scaled)\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "# 定義自編碼器模型\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(X_train.shape[1], 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, X_train.shape[1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型和優化器\n",
    "model = AutoEncoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# 訓練模型\n",
    "for epoch in range(100):\n",
    "    for data in train_loader:\n",
    "        X = data[0]\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, 100, loss.item()))\n",
    "\n",
    "# 在測試數據上進行異常檢測\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_output = model(X_test_tensor)\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    losses = mse_loss(test_output, X_test_tensor)\n",
    "    anomaly_scores = torch.mean(losses, dim=1)\n",
    "\n",
    "# 輸出結果\n",
    "result = pd.DataFrame(list(range(len(anomaly_scores))), columns=['id'])\n",
    "result['outliers'] = anomaly_scores.numpy()\n",
    "result.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
