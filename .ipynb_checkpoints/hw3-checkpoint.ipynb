{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667c3e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.9741\n",
      "epoch [11/100], loss:0.2397\n",
      "epoch [21/100], loss:0.1025\n",
      "epoch [31/100], loss:0.0503\n",
      "epoch [41/100], loss:0.0188\n",
      "epoch [51/100], loss:0.0106\n",
      "epoch [61/100], loss:0.0064\n",
      "epoch [71/100], loss:0.0038\n",
      "epoch [81/100], loss:0.0025\n",
      "epoch [91/100], loss:0.0017\n",
      "epoch [101/100], loss:0.0014\n",
      "epoch [111/100], loss:0.0011\n",
      "epoch [121/100], loss:0.0010\n",
      "epoch [131/100], loss:0.0009\n",
      "epoch [141/100], loss:0.0008\n",
      "epoch [151/100], loss:0.0007\n",
      "epoch [161/100], loss:0.0006\n",
      "epoch [171/100], loss:0.0006\n",
      "epoch [181/100], loss:0.0005\n",
      "epoch [191/100], loss:0.0005\n",
      "epoch [201/100], loss:0.0005\n",
      "epoch [211/100], loss:0.0004\n",
      "epoch [221/100], loss:0.0005\n",
      "epoch [231/100], loss:0.0004\n",
      "epoch [241/100], loss:0.0004\n",
      "epoch [251/100], loss:0.0004\n",
      "epoch [261/100], loss:0.0003\n",
      "epoch [271/100], loss:0.0003\n",
      "epoch [281/100], loss:0.0003\n",
      "epoch [291/100], loss:0.0003\n",
      "epoch [301/100], loss:0.0003\n",
      "epoch [311/100], loss:0.0003\n",
      "epoch [321/100], loss:0.0003\n",
      "epoch [331/100], loss:0.0003\n",
      "epoch [341/100], loss:0.0002\n",
      "epoch [351/100], loss:0.0003\n",
      "epoch [361/100], loss:0.0003\n",
      "epoch [371/100], loss:0.0003\n",
      "epoch [381/100], loss:0.0002\n",
      "epoch [391/100], loss:0.0002\n",
      "epoch [401/100], loss:0.0002\n",
      "epoch [411/100], loss:0.0002\n",
      "epoch [421/100], loss:0.0002\n",
      "epoch [431/100], loss:0.0002\n",
      "epoch [441/100], loss:0.0002\n",
      "epoch [451/100], loss:0.0002\n",
      "epoch [461/100], loss:0.0002\n",
      "epoch [471/100], loss:0.0002\n",
      "epoch [481/100], loss:0.0002\n",
      "epoch [491/100], loss:0.0002\n",
      "epoch [501/100], loss:0.0002\n",
      "epoch [511/100], loss:0.0002\n",
      "epoch [521/100], loss:0.0002\n",
      "epoch [531/100], loss:0.0002\n",
      "epoch [541/100], loss:0.0002\n",
      "epoch [551/100], loss:0.0002\n",
      "epoch [561/100], loss:0.0002\n",
      "epoch [571/100], loss:0.0002\n",
      "epoch [581/100], loss:0.0002\n",
      "epoch [591/100], loss:0.0002\n",
      "epoch [601/100], loss:0.0001\n",
      "epoch [611/100], loss:0.0002\n",
      "epoch [621/100], loss:0.0001\n",
      "epoch [631/100], loss:0.0001\n",
      "epoch [641/100], loss:0.0001\n",
      "epoch [651/100], loss:0.0002\n",
      "epoch [661/100], loss:0.0001\n",
      "epoch [671/100], loss:0.0001\n",
      "epoch [681/100], loss:0.0001\n",
      "epoch [691/100], loss:0.0002\n",
      "epoch [701/100], loss:0.0001\n",
      "epoch [711/100], loss:0.0001\n",
      "epoch [721/100], loss:0.0001\n",
      "epoch [731/100], loss:0.0001\n",
      "epoch [741/100], loss:0.0001\n",
      "epoch [751/100], loss:0.0001\n",
      "epoch [761/100], loss:0.0001\n",
      "epoch [771/100], loss:0.0001\n",
      "epoch [781/100], loss:0.0001\n",
      "epoch [791/100], loss:0.0001\n",
      "epoch [801/100], loss:0.0001\n",
      "epoch [811/100], loss:0.0001\n",
      "epoch [821/100], loss:0.0001\n",
      "epoch [831/100], loss:0.0001\n",
      "epoch [841/100], loss:0.0001\n",
      "epoch [851/100], loss:0.0001\n",
      "epoch [861/100], loss:0.0001\n",
      "epoch [871/100], loss:0.0001\n",
      "epoch [881/100], loss:0.0001\n",
      "epoch [891/100], loss:0.0001\n",
      "epoch [901/100], loss:0.0001\n",
      "epoch [911/100], loss:0.0001\n",
      "epoch [921/100], loss:0.0001\n",
      "epoch [931/100], loss:0.0001\n",
      "epoch [941/100], loss:0.0001\n",
      "epoch [951/100], loss:0.0001\n",
      "epoch [961/100], loss:0.0001\n",
      "epoch [971/100], loss:0.0001\n",
      "epoch [981/100], loss:0.0001\n",
      "epoch [991/100], loss:0.0001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 讀取訓練和測試數據\n",
    "train_data = pd.read_csv('training.csv')\n",
    "test_data = pd.read_csv('test_X.csv')\n",
    "\n",
    "# 將字母標籤轉換為二元形式\n",
    "train_data['lettr'] = train_data['lettr'].apply(lambda x: 1 if x in ['B','H','P','W','R','M'] else -1)\n",
    "\n",
    "# 切分訓練數據的特徵和標籤\n",
    "X_train = train_data.drop('lettr', axis=1)\n",
    "y_train = train_data['lettr']\n",
    "\n",
    "# 使用StandardScaler進行數據正規化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "\n",
    "# 將資料轉換為 torch.Tensor\n",
    "X_train_tensor = torch.Tensor(X_train_scaled)\n",
    "X_test_tensor = torch.Tensor(X_test_scaled)\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor), batch_size=256, shuffle=True)\n",
    "\n",
    "# 定義自編碼器模型\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(X_train.shape[1], 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, X_train.shape[1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型和優化器\n",
    "model = AutoEncoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 訓練模型\n",
    "for epoch in range(1000):\n",
    "    for data in train_loader:\n",
    "        X = data[0]\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, 100, loss.item()))\n",
    "\n",
    "# 在測試數據上進行異常檢測\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_output = model(X_test_tensor)\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    losses = mse_loss(test_output, X_test_tensor)\n",
    "    anomaly_scores = torch.mean(losses, dim=1)\n",
    "\n",
    "# 輸出結果\n",
    "result = pd.DataFrame(list(range(len(anomaly_scores))), columns=['id'])\n",
    "result['outliers'] = anomaly_scores.numpy()\n",
    "result.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25cc4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
